# UGATIT-reproducibility
The 'Untitled0.ipynb' file in each folder is used to train the model in that folder.

The training code used in the Jupyter notebook is `!python main.py --dataset cat2dog --light True --iteration 50000 --save_freq 1000 --print_freq 1000 --resume True`

The team of the coursework train the model on Google Colab Pro using the light version which you can specify in the training code. 

`--iteration` is the number of training epochs.

`--save_freq 1000` means the model will save the '.pt' file which is the parameter of the network per 1000 epochs.

`--print_freq 1000` means the model will save the pictures generated by the generator per 1000 epochs.

`--light True` means use the light version of the code.

`--resume True` means you can use the latest saved '.pt' file to resume the training insteading of training from the begining. For example, after 10000 epochs, the computer crashes, then you can start from 10000 epochs insteading of from 0 epoch.

If you want to use the full version of the code instead of the light version, use good GPU. The team successfully run it on a Titan RTX with 24G memory. However, considering about the cost to use a better GPU, the team chooses to run the light version of the code on the Google Colab Pro which is claimed to yield similar results compared with the full version code.

### The code for the ablation study for the anxiliary classifiers
As shown in the original essay, the auxiliary classifiers are applied on the encoder feature map after the encoder to calculate the weight. In the “networks.py” file, the “forward” functions in the “ResnetGenerator” class and the “Discriminator” class build the whole process of the generator and the discriminator, respectively. To delete the use of the auxiliary classifier, one can simply put the output of the encoder as the input of a fully connected layer before the decoder. This can be solved by commenting on the following code since this piece of code changes the variable “x” using the result of the auxiliary classifiers. If the user still wants the heatmap as one of the outputs of this function, he can replace the “x” in this piece of code by another variable name instead of commenting. This method applies both on the auxiliary classifier in the generator and the discriminator.

### The code for the ablation study for the AdaLIN

To change the AdaLIN to LN and IN, one can simply change the number 0.9 in the ‘self.rho.data.fill\_()’ function in the “adaLIN” class to 0 and 1, respectively.

### The results foler
In "result" foler, each dataset will have a folder named by its name. And the "img" foler have the pictures saved by "print_freq" per 1000 epochs. From top to bottom are the realA picture, the heatmap of the picture realA after B2A generator, the picture of realA after B2A generator, the heatmap of the picture realA after A2B generator, the picture of the realA after A2B generator, and the picture of realA after A2B generator and then B2A generator. The condition is similar for realB pictures. (realA are pictures from "trainA" dataset.)

The "model" folder contains the saved model which is ".pt" file by the "save_freq".

The "test" folder is the images generated during test phrase.

The team has changed the code in the "test" phrase in the "UGATIT.py" file to generate the original pictures and the generated pictures in "realA","realB","fakeA", "fakeB" folders to calculate the FID easier.

